{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##优化过拟合版本\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageFile\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models\n",
    "from torchvision import transforms as T\n",
    "from torchvision.transforms.functional import InterpolationMode, resize\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# 防止 PIL 出错,尽量读取jpg\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\" 修改后模型架构，增加 Dropout 防止过拟合 \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.net = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.net = models.resnet50()\n",
    "        \n",
    "        # 修改 ResNet50 的全连接层（fc）\n",
    "        self.net.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),  # 先缩小维度\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),  # 添加 Dropout\n",
    "            nn.Linear(1024, 58)  # 输出类别数\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    classes = [\n",
    "        '5kilometer',\n",
    "        '15kilometer',\n",
    "        '30kilometer',\n",
    "        '40kilometer',\n",
    "        '50kilometer',\n",
    "        '60kilometer',\n",
    "        '70kilometer',\n",
    "        '90kilometer',\n",
    "        'No Left Turn or Straight Ahead',\n",
    "        'No Right Turn or Straight Ahead',\n",
    "        'No Straight Ahead',\n",
    "        'No Left Turn',\n",
    "        'No Left or Right Turn',\n",
    "        'No Right Turn',\n",
    "        'No Overtaking',\n",
    "        'No U-turn',\n",
    "        'No Entry for Motor Vehicles',\n",
    "        'No Horn',\n",
    "        'End Speed Limit 40',\n",
    "        'End Speed Limit 50',\n",
    "        'Turn Right or Go Straight Ahead',\n",
    "        'Ahead Only',\n",
    "        'Left Turn Only',\n",
    "        'Left or Right Turn Only',\n",
    "        'Right Turn Only',\n",
    "        'Keep Left',\n",
    "        'Keep Right',\n",
    "        'Roundabout',\n",
    "        'Motor Vehicles Only',\n",
    "        'Sound Horn',\n",
    "        'Bicycles Only',\n",
    "        'U-turn Only',\n",
    "        'Divided Road Ahead',\n",
    "        'Traffic Signals Ahead',\n",
    "        'General Warning',\n",
    "        'Pedestrian Crossing Ahead',\n",
    "        'Cyclists Ahead',\n",
    "        'Children Crossing Ahead',\n",
    "        'Right Curve Ahead',\n",
    "        'Left Curve Ahead',\n",
    "        'Steep Descent',\n",
    "        'Steep Ascent',\n",
    "        'SLOW',\n",
    "        'Side Road Junction Ahead',\n",
    "        'Side Road Junction (left) Ahead',\n",
    "        'Built-up Area Warning',\n",
    "        'Winding Road Ahead',\n",
    "        'train ahead',\n",
    "        'Road Works Ahead',\n",
    "        'Continuous sharp turn sign',\n",
    "        'Railway level crossing',\n",
    "        'Rear End Collision',\n",
    "        'STOP',\n",
    "        'No Entry for Vehicles',\n",
    "        'No Stopping',\n",
    "        'No Entry',\n",
    "        'Give Way',\n",
    "        'Stop - Police'\n",
    "    ]\n",
    "\n",
    "    label = {\n",
    "        c: index\n",
    "        for index, c in enumerate(classes)\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root=r'./data',\n",
    "        is_train=True\n",
    "    ):\n",
    "        self.path = os.path.join(root, 'train' if is_train else 'validation')\n",
    "        self.images = []\n",
    "        self.merge_images()\n",
    "        self.t = T.Compose([\n",
    "            T.RandomResizedCrop(224, scale=(0.8, 1.0)),  # 随机裁剪\n",
    "            T.RandomHorizontalFlip(p=0.5),  # 随机水平翻转\n",
    "            T.RandomRotation(15),  # 轻微旋转\n",
    "            T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # 颜色抖动\n",
    "            T.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # 轻微平移\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 归一化\n",
    "        ])\n",
    "\n",
    "\n",
    "    def merge_images(self):\n",
    "        valid_exts = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "        for c in self.classes:\n",
    "            p = Path(self.path) / c\n",
    "            if not p.exists():\n",
    "                continue\n",
    "            for img in p.iterdir():\n",
    "                if img.suffix.lower() in valid_exts:\n",
    "                    self.images.append((str(img), c))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, image_label = self.images[index]\n",
    "        image_label = self.label[image_label]\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")  # 确保是 RGB\n",
    "            image = self.t(image)\n",
    "            return image, torch.LongTensor([image_label])\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Skipping corrupted image {image_path}. Error: {e}\")\n",
    "            return self.__getitem__((index + 1) % len(self.images))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataload(\n",
    "    is_train=True,\n",
    "    batch_size=64\n",
    "):\n",
    "    dataset = MyDataset(is_train=is_train)\n",
    "    return DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=is_train\n",
    "    )\n",
    "\n",
    "\n",
    "def train_batch(\n",
    "    batch,\n",
    "    optimizer,\n",
    "    loss,\n",
    "    net\n",
    "):\n",
    "    optimizer.zero_grad()\n",
    "    if torch.cuda.is_available():\n",
    "        batch = [i.cuda() for i in batch]\n",
    "    X, Y = batch\n",
    "    Y_hat = net(X)\n",
    "    #Y_hat = F.softmax(Y_hat, -1)\n",
    "    l = loss(Y_hat, Y.flatten())\n",
    "    l.sum().backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        return l.sum().cpu()\n",
    "    \n",
    "def test_batch(\n",
    "    batch,\n",
    "    net,\n",
    "    loss\n",
    "):\n",
    "    if torch.cuda.is_available():\n",
    "        batch = [i.cuda() for i in batch]\n",
    "    X, Y = batch\n",
    "    Y_hat = net(X)\n",
    "    #Y_hat = F.softmax(Y_hat, -1)\n",
    "    l = loss(Y_hat, Y.flatten())\n",
    "    return l.sum().cpu()\n",
    "\n",
    "\n",
    "def save_checkpoint(net, path, epoch):\n",
    "    torch.save(net.state_dict(), path)\n",
    "    print(f'已保存模型 (Epoch {epoch})')  #  添加 epoch 信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    epoch,\n",
    "    lr=1e-4, #更改\n",
    "    train_batch_size=32,\n",
    "    test_batch_size=32,\n",
    "    path='parameters_Resnet50.cpt'\n",
    "):\n",
    "    net = Net()\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(net.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epoch) #更改\n",
    "    dataset = dataload(is_train=True, batch_size=train_batch_size)\n",
    "    valid_dataset = dataload(is_train=False, batch_size=test_batch_size)\n",
    "    \n",
    "    writer = SummaryWriter(log_dir='logs')  # 指定日志目录\n",
    "\n",
    "    min_mean_loss = None\n",
    "    min_valid_loss = None\n",
    "\n",
    "    for i in range(epoch):\n",
    "        print(f'epoch: {i+1}/{epoch}')\n",
    "        # 打印当前学习率，便于监控\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'当前学习率: {current_lr:.6f}')\n",
    "        \n",
    "        mean_loss = []\n",
    "        mean_valid_loss = []\n",
    "        net.train()\n",
    "        for batch in dataset:\n",
    "            l = train_batch(\n",
    "                batch=batch,\n",
    "                optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                net=net\n",
    "            )\n",
    "            mean_loss.append(l)\n",
    "\n",
    "        with torch.no_grad(): #关闭梯度计算\n",
    "            net.eval()\n",
    "            for batch in valid_dataset:\n",
    "                l = test_batch(batch=batch, net=net, loss=loss)\n",
    "                mean_valid_loss.append(l)\n",
    "\n",
    "        writer.add_scalar('Resnet50_Loss/train', np.mean(mean_loss), i+1)\n",
    "        writer.add_scalar('Resnet50_Loss/test', np.mean(mean_valid_loss), i+1)\n",
    "        \n",
    "        print(f'train loss: {np.mean(mean_loss):.5f}')\n",
    "        print(f'test loss: {np.mean(mean_valid_loss):.5f}')\n",
    "\n",
    "        # if min_mean_loss is None or min_mean_loss > np.mean(mean_loss):\n",
    "        #     save_checkpoint(net, path, i+1)  #  传递当前 epoch\n",
    "        #     min_mean_loss = np.mean(mean_loss)\n",
    "            \n",
    "        if min_valid_loss is None or min_valid_loss > np.mean(mean_valid_loss): #更改\n",
    "            save_checkpoint(net, path, i+1)  # 传递当前 epoch\n",
    "            min_valid_loss = np.mean(mean_valid_loss)\n",
    "            \n",
    "        #让学习率衰减\n",
    "        scheduler.step()\n",
    "            \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net_from_hdf(path):\n",
    "    net = Net()  # 先实例化网络结构\n",
    "    net.load_state_dict(torch.load(path, map_location=torch.device('cuda:0')))  # 只加载权重\n",
    "    net.eval()\n",
    "    return net\n",
    "\n",
    "def predict(X, Y, net=None):\n",
    "    return net(X).argmax(-1).flatten(), Y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/100\n",
      "当前学习率: 0.000100\n",
      "train loss: 3.40104\n",
      "test loss: 3.55096\n",
      "已保存模型 (Epoch 1)\n",
      "epoch: 2/100\n",
      "当前学习率: 0.000100\n",
      "train loss: 2.77887\n",
      "test loss: 3.14914\n",
      "已保存模型 (Epoch 2)\n",
      "epoch: 3/100\n",
      "当前学习率: 0.000100\n",
      "train loss: 2.36102\n",
      "test loss: 2.70288\n",
      "已保存模型 (Epoch 3)\n",
      "epoch: 4/100\n",
      "当前学习率: 0.000100\n",
      "train loss: 1.94401\n",
      "test loss: 2.43751\n",
      "已保存模型 (Epoch 4)\n",
      "epoch: 5/100\n",
      "当前学习率: 0.000100\n",
      "train loss: 1.60678\n",
      "test loss: 2.49246\n",
      "epoch: 6/100\n",
      "当前学习率: 0.000099\n",
      "train loss: 1.33995\n",
      "test loss: 2.60530\n",
      "epoch: 7/100\n",
      "当前学习率: 0.000099\n",
      "train loss: 1.11906\n",
      "test loss: 2.07296\n",
      "已保存模型 (Epoch 7)\n",
      "epoch: 8/100\n",
      "当前学习率: 0.000099\n",
      "train loss: 0.93252\n",
      "test loss: 1.67700\n",
      "已保存模型 (Epoch 8)\n",
      "epoch: 9/100\n",
      "当前学习率: 0.000098\n",
      "train loss: 0.77976\n",
      "test loss: 1.55289\n",
      "已保存模型 (Epoch 9)\n",
      "epoch: 10/100\n",
      "当前学习率: 0.000098\n",
      "train loss: 0.62543\n",
      "test loss: 1.49299\n",
      "已保存模型 (Epoch 10)\n",
      "epoch: 11/100\n",
      "当前学习率: 0.000098\n",
      "train loss: 0.54161\n",
      "test loss: 1.17674\n",
      "已保存模型 (Epoch 11)\n",
      "epoch: 12/100\n",
      "当前学习率: 0.000097\n",
      "train loss: 0.44220\n",
      "test loss: 1.35473\n",
      "epoch: 13/100\n",
      "当前学习率: 0.000096\n",
      "train loss: 0.36352\n",
      "test loss: 1.05243\n",
      "已保存模型 (Epoch 13)\n",
      "epoch: 14/100\n",
      "当前学习率: 0.000096\n",
      "train loss: 0.38583\n",
      "test loss: 1.54575\n",
      "epoch: 15/100\n",
      "当前学习率: 0.000095\n",
      "train loss: 0.28322\n",
      "test loss: 0.78957\n",
      "已保存模型 (Epoch 15)\n",
      "epoch: 16/100\n",
      "当前学习率: 0.000095\n",
      "train loss: 0.28930\n",
      "test loss: 0.85353\n",
      "epoch: 17/100\n",
      "当前学习率: 0.000094\n",
      "train loss: 0.24231\n",
      "test loss: 0.90882\n",
      "epoch: 18/100\n",
      "当前学习率: 0.000093\n",
      "train loss: 0.20367\n",
      "test loss: 1.07243\n",
      "epoch: 19/100\n",
      "当前学习率: 0.000092\n",
      "train loss: 0.23024\n",
      "test loss: 0.89746\n",
      "epoch: 20/100\n",
      "当前学习率: 0.000091\n",
      "train loss: 0.20099\n",
      "test loss: 0.84257\n",
      "epoch: 21/100\n",
      "当前学习率: 0.000090\n",
      "train loss: 0.17426\n",
      "test loss: 0.78896\n",
      "已保存模型 (Epoch 21)\n",
      "epoch: 22/100\n",
      "当前学习率: 0.000090\n",
      "train loss: 0.15929\n",
      "test loss: 0.77537\n",
      "已保存模型 (Epoch 22)\n",
      "epoch: 23/100\n",
      "当前学习率: 0.000089\n",
      "train loss: 0.15242\n",
      "test loss: 0.69184\n",
      "已保存模型 (Epoch 23)\n",
      "epoch: 24/100\n",
      "当前学习率: 0.000088\n",
      "train loss: 0.14813\n",
      "test loss: 0.80735\n",
      "epoch: 25/100\n",
      "当前学习率: 0.000086\n",
      "train loss: 0.16197\n",
      "test loss: 0.74722\n",
      "epoch: 26/100\n",
      "当前学习率: 0.000085\n",
      "train loss: 0.11289\n",
      "test loss: 0.65943\n",
      "已保存模型 (Epoch 26)\n",
      "epoch: 27/100\n",
      "当前学习率: 0.000084\n",
      "train loss: 0.14893\n",
      "test loss: 0.67874\n",
      "epoch: 28/100\n",
      "当前学习率: 0.000083\n",
      "train loss: 0.14097\n",
      "test loss: 0.77914\n",
      "epoch: 29/100\n",
      "当前学习率: 0.000082\n",
      "train loss: 0.09099\n",
      "test loss: 0.56160\n",
      "已保存模型 (Epoch 29)\n",
      "epoch: 30/100\n",
      "当前学习率: 0.000081\n",
      "train loss: 0.10414\n",
      "test loss: 0.92528\n",
      "epoch: 31/100\n",
      "当前学习率: 0.000079\n",
      "train loss: 0.10385\n",
      "test loss: 0.66199\n",
      "epoch: 32/100\n",
      "当前学习率: 0.000078\n",
      "train loss: 0.12487\n",
      "test loss: 0.69458\n",
      "epoch: 33/100\n",
      "当前学习率: 0.000077\n",
      "train loss: 0.10441\n",
      "test loss: 0.65256\n",
      "epoch: 34/100\n",
      "当前学习率: 0.000075\n",
      "train loss: 0.12744\n",
      "test loss: 0.66808\n",
      "epoch: 35/100\n",
      "当前学习率: 0.000074\n",
      "train loss: 0.09578\n",
      "test loss: 0.60645\n",
      "epoch: 36/100\n",
      "当前学习率: 0.000073\n",
      "train loss: 0.07343\n",
      "test loss: 0.60799\n",
      "epoch: 37/100\n",
      "当前学习率: 0.000071\n",
      "train loss: 0.08725\n",
      "test loss: 0.60001\n",
      "epoch: 38/100\n",
      "当前学习率: 0.000070\n",
      "train loss: 0.07624\n",
      "test loss: 0.55924\n",
      "已保存模型 (Epoch 38)\n",
      "epoch: 39/100\n",
      "当前学习率: 0.000068\n",
      "train loss: 0.09596\n",
      "test loss: 0.68407\n",
      "epoch: 40/100\n",
      "当前学习率: 0.000067\n",
      "train loss: 0.08008\n",
      "test loss: 0.58828\n",
      "epoch: 41/100\n",
      "当前学习率: 0.000065\n",
      "train loss: 0.06274\n",
      "test loss: 0.53803\n",
      "已保存模型 (Epoch 41)\n",
      "epoch: 42/100\n",
      "当前学习率: 0.000064\n",
      "train loss: 0.07721\n",
      "test loss: 0.73765\n",
      "epoch: 43/100\n",
      "当前学习率: 0.000062\n",
      "train loss: 0.08334\n",
      "test loss: 0.60404\n",
      "epoch: 44/100\n",
      "当前学习率: 0.000061\n",
      "train loss: 0.08021\n",
      "test loss: 0.68761\n",
      "epoch: 45/100\n",
      "当前学习率: 0.000059\n",
      "train loss: 0.06217\n",
      "test loss: 0.51234\n",
      "已保存模型 (Epoch 45)\n",
      "epoch: 46/100\n",
      "当前学习率: 0.000058\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(epoch, lr, train_batch_size, test_batch_size, path)\u001b[39m\n\u001b[32m     29\u001b[39m mean_valid_loss = []\n\u001b[32m     30\u001b[39m net.train()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnet\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmean_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 103\u001b[39m, in \u001b[36mMyDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    102\u001b[39m     image = Image.open(image_path).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# 确保是 RGB\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m image, torch.LongTensor([image_label])\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:1529\u001b[39m, in \u001b[36mRandomAffine.forward\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m   1525\u001b[39m img_size = [width, height]  \u001b[38;5;66;03m# flip for keeping BC on get_params call\u001b[39;00m\n\u001b[32m   1527\u001b[39m ret = \u001b[38;5;28mself\u001b[39m.get_params(\u001b[38;5;28mself\u001b[39m.degrees, \u001b[38;5;28mself\u001b[39m.translate, \u001b[38;5;28mself\u001b[39m.scale, \u001b[38;5;28mself\u001b[39m.shear, img_size)\n\u001b[32m-> \u001b[39m\u001b[32m1529\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43maffine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1228\u001b[39m, in \u001b[36maffine\u001b[39m\u001b[34m(img, angle, translate, scale, shear, interpolation, fill, center)\u001b[39m\n\u001b[32m   1226\u001b[39m     matrix = _get_inverse_affine_matrix(center, angle, translate, scale, shear)\n\u001b[32m   1227\u001b[39m     pil_interpolation = pil_modes_mapping[interpolation]\n\u001b[32m-> \u001b[39m\u001b[32m1228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[43m.\u001b[49m\u001b[43maffine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1230\u001b[39m center_f = [\u001b[32m0.0\u001b[39m, \u001b[32m0.0\u001b[39m]\n\u001b[32m   1231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m center \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:300\u001b[39m, in \u001b[36maffine\u001b[39m\u001b[34m(img, matrix, interpolation, fill)\u001b[39m\n\u001b[32m    298\u001b[39m output_size = img.size\n\u001b[32m    299\u001b[39m opts = _parse_fill(fill, img)\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAFFINE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\PIL\\Image.py:2879\u001b[39m, in \u001b[36mImage.transform\u001b[39m\u001b[34m(self, size, method, data, resample, fill, fillcolor)\u001b[39m\n\u001b[32m   2876\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mmissing method data\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2877\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2879\u001b[39m im = \u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfillcolor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.palette:\n\u001b[32m   2881\u001b[39m     im.palette = \u001b[38;5;28mself\u001b[39m.palette.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\anaconda3\\envs\\yolo\\Lib\\site-packages\\PIL\\Image.py:3136\u001b[39m, in \u001b[36mnew\u001b[39m\u001b[34m(mode, size, color)\u001b[39m\n\u001b[32m   3134\u001b[39m         im.palette = ImagePalette.ImagePalette()\n\u001b[32m   3135\u001b[39m         color = im.palette.getcolor(color_ints)\n\u001b[32m-> \u001b[39m\u001b[32m3136\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m im._new(\u001b[43mcore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 训练\n",
    "    train(\n",
    "        epoch=100,\n",
    "        train_batch_size=16,\n",
    "        test_batch_size=16\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Accuracy: 85.96%\n",
      "\n",
      "分类正确率：\n",
      "5kilometer: 85.71% (12/14)\n",
      "15kilometer: 83.33% (10/12)\n",
      "30kilometer: 98.33% (59/60)\n",
      "40kilometer: 100.00% (84/84)\n",
      "50kilometer: 91.38% (53/58)\n",
      "60kilometer: 68.00% (34/50)\n",
      "70kilometer: 100.00% (30/30)\n",
      "90kilometer: 84.00% (42/50)\n",
      "No Left Turn or Straight Ahead: 92.86% (13/14)\n",
      "No Right Turn or Straight Ahead: 0.00% (0/2)\n",
      "No Straight Ahead: 96.67% (58/60)\n",
      "No Left Turn: 93.08% (121/130)\n",
      "No Left or Right Turn: 100.00% (22/22)\n",
      "No Right Turn: 78.26% (72/92)\n",
      "No Overtaking: 100.00% (12/12)\n",
      "No U-turn: 50.00% (18/36)\n",
      "No Entry for Motor Vehicles: 97.37% (74/76)\n",
      "No Horn: 78.57% (66/84)\n",
      "End Speed Limit 40: 0.00% (0/0)\n",
      "End Speed Limit 50: 0.00% (0/0)\n",
      "Turn Right or Go Straight Ahead: 100.00% (2/2)\n",
      "Ahead Only: 75.00% (9/12)\n",
      "Left Turn Only: 62.50% (5/8)\n",
      "Left or Right Turn Only: 60.00% (6/10)\n",
      "Right Turn Only: 84.62% (22/26)\n",
      "Keep Left: 100.00% (36/36)\n",
      "Keep Right: 90.30% (121/134)\n",
      "Roundabout: 100.00% (24/24)\n",
      "Motor Vehicles Only: 89.71% (61/68)\n",
      "Sound Horn: 100.00% (26/26)\n",
      "Bicycles Only: 91.18% (31/34)\n",
      "U-turn Only: 88.89% (16/18)\n",
      "Divided Road Ahead: 100.00% (2/2)\n",
      "Traffic Signals Ahead: 100.00% (22/22)\n",
      "General Warning: 78.57% (22/28)\n",
      "Pedestrian Crossing Ahead: 100.00% (46/46)\n",
      "Cyclists Ahead: 83.33% (10/12)\n",
      "Children Crossing Ahead: 96.15% (25/26)\n",
      "Right Curve Ahead: 5.00% (2/40)\n",
      "Left Curve Ahead: 50.00% (15/30)\n",
      "Steep Descent: 100.00% (8/8)\n",
      "Steep Ascent: 25.00% (2/8)\n",
      "SLOW: 100.00% (18/18)\n",
      "Side Road Junction Ahead: 72.41% (84/116)\n",
      "Side Road Junction (left) Ahead: 4.17% (1/24)\n",
      "Built-up Area Warning: 100.00% (2/2)\n",
      "Winding Road Ahead: 92.86% (13/14)\n",
      "train ahead: 100.00% (10/10)\n",
      "Road Works Ahead: 100.00% (6/6)\n",
      "Continuous sharp turn sign: 100.00% (42/42)\n",
      "Railway level crossing: 95.00% (19/20)\n",
      "Rear End Collision: 100.00% (4/4)\n",
      "STOP: 100.00% (30/30)\n",
      "No Entry for Vehicles: 95.24% (20/21)\n",
      "No Stopping: 98.86% (174/176)\n",
      "No Entry: 67.24% (39/58)\n",
      "Give Way: 95.00% (38/40)\n",
      "Stop - Police: 100.00% (7/7)\n"
     ]
    }
   ],
   "source": [
    "path = 'parameters_Resnet50.cpt' \n",
    "net = load_net_from_hdf(path)\n",
    "\n",
    "classes = [\n",
    "    '5kilometer',\n",
    "    '15kilometer',\n",
    "    '30kilometer',\n",
    "    '40kilometer',\n",
    "    '50kilometer',\n",
    "    '60kilometer',\n",
    "    '70kilometer',\n",
    "    '90kilometer',\n",
    "    'No Left Turn or Straight Ahead',\n",
    "    'No Right Turn or Straight Ahead',\n",
    "    'No Straight Ahead',\n",
    "    'No Left Turn',\n",
    "    'No Left or Right Turn',\n",
    "    'No Right Turn',\n",
    "    'No Overtaking',\n",
    "    'No U-turn',\n",
    "    'No Entry for Motor Vehicles',\n",
    "    'No Horn',\n",
    "    'End Speed Limit 40',\n",
    "    'End Speed Limit 50',\n",
    "    'Turn Right or Go Straight Ahead',\n",
    "    'Ahead Only',\n",
    "    'Left Turn Only',\n",
    "    'Left or Right Turn Only',\n",
    "    'Right Turn Only',\n",
    "    'Keep Left',\n",
    "    'Keep Right',\n",
    "    'Roundabout',\n",
    "    'Motor Vehicles Only',\n",
    "    'Sound Horn',\n",
    "    'Bicycles Only',\n",
    "    'U-turn Only',\n",
    "    'Divided Road Ahead',\n",
    "    'Traffic Signals Ahead',\n",
    "    'General Warning',\n",
    "    'Pedestrian Crossing Ahead',\n",
    "    'Cyclists Ahead',\n",
    "    'Children Crossing Ahead',\n",
    "    'Right Curve Ahead',\n",
    "    'Left Curve Ahead',\n",
    "    'Steep Descent',\n",
    "    'Steep Ascent',\n",
    "    'SLOW',\n",
    "    'Side Road Junction Ahead',\n",
    "    'Side Road Junction (left) Ahead',\n",
    "    'Built-up Area Warning',\n",
    "    'Winding Road Ahead',\n",
    "    'train ahead',\n",
    "    'Road Works Ahead',\n",
    "    'Continuous sharp turn sign',\n",
    "    'Railway level crossing',\n",
    "    'Rear End Collision',\n",
    "    'STOP',\n",
    "    'No Entry for Vehicles',\n",
    "    'No Stopping',\n",
    "    'No Entry',\n",
    "    'Give Way',\n",
    "    'Stop - Police'\n",
    "]\n",
    "\n",
    "# **计算最终的验证集准确率**\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "\n",
    "# **计算每个类别的正确率**\n",
    "correct_counts = {c: 0 for c in classes}  # 统计每个类别预测正确的样本数\n",
    "total_counts = {c: 0 for c in classes}    # 统计每个类别的总样本数\n",
    "\n",
    "for X, Y in dataload(False, batch_size=16):\n",
    "    Y_hat, Y = predict(X, Y, net)\n",
    "    \n",
    "    total_correct += (Y_hat == Y).sum().item()  # 总正确数\n",
    "    total_samples += Y.shape[0]  # 总样本数\n",
    "    \n",
    "    for i in range(Y.shape[0]):\n",
    "        true_class = classes[Y[i].item()]\n",
    "        pred_class = classes[Y_hat[i].item()]\n",
    "\n",
    "        total_counts[true_class] += 1  # 该类别总样本数+1\n",
    "        if true_class == pred_class:\n",
    "            correct_counts[true_class] += 1  # 该类别预测正确数+1\n",
    "\n",
    "# **打印最终整体准确率**\n",
    "accuracy = total_correct / total_samples * 100\n",
    "print(f'Final Validation Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# **打印每个类别的准确率**\n",
    "print(\"\\n分类正确率：\")\n",
    "for c in classes:\n",
    "    class_acc = (correct_counts[c] / total_counts[c]) * 100 if total_counts[c] > 0 else 0\n",
    "    print(f\"{c}: {class_acc:.2f}% ({correct_counts[c]}/{total_counts[c]})\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
